{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook illustrates simple membership inference attacks against an overfit version of the teacher model\n",
    "# and a version of the student model trained to predict outputs of the overfit teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes10/klkehl/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_data = pd.read_csv('/data/clin_notes_outcomes/profile_3-2023/derived_data/labeled_medonc_prissmm_mixedisprog.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32173 entries, 0 to 39190\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0.1              32173 non-null  int64  \n",
      " 1   dfci_mrn                  32173 non-null  float64\n",
      " 2   cancer_type               32173 non-null  object \n",
      " 3   date                      32173 non-null  object \n",
      " 4   any_cancer                32173 non-null  int64  \n",
      " 5   progression               32173 non-null  int64  \n",
      " 6   response                  32173 non-null  int64  \n",
      " 7   Unnamed: 0                32173 non-null  int64  \n",
      " 8   text                      32173 non-null  object \n",
      " 9   PROVIDER_DEPARTMENT       32173 non-null  object \n",
      " 10  patient_id                32173 non-null  int64  \n",
      " 11  hybrid_death_ind          32173 non-null  object \n",
      " 12  hybrid_death_dt           19552 non-null  object \n",
      " 13  primary_cancer_diagnosis  32173 non-null  object \n",
      " 14  genomics_date             32173 non-null  object \n",
      " 15  after_profile             32173 non-null  int64  \n",
      " 16  split                     32173 non-null  object \n",
      "dtypes: float64(1), int64(7), object(9)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training = phi_data[phi_data.split=='train']\n",
    "training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2917"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.dfci_mrn.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3636 entries, 362 to 39187\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0.1              3636 non-null   int64  \n",
      " 1   dfci_mrn                  3636 non-null   float64\n",
      " 2   cancer_type               3636 non-null   object \n",
      " 3   date                      3636 non-null   object \n",
      " 4   any_cancer                3636 non-null   int64  \n",
      " 5   progression               3636 non-null   int64  \n",
      " 6   response                  3636 non-null   int64  \n",
      " 7   Unnamed: 0                3636 non-null   int64  \n",
      " 8   text                      3636 non-null   object \n",
      " 9   PROVIDER_DEPARTMENT       3636 non-null   object \n",
      " 10  patient_id                3636 non-null   int64  \n",
      " 11  hybrid_death_ind          3636 non-null   object \n",
      " 12  hybrid_death_dt           2416 non-null   object \n",
      " 13  primary_cancer_diagnosis  3636 non-null   object \n",
      " 14  genomics_date             3636 non-null   object \n",
      " 15  after_profile             3636 non-null   int64  \n",
      " 16  split                     3636 non-null   object \n",
      "dtypes: float64(1), int64(7), object(9)\n",
      "memory usage: 511.3+ KB\n"
     ]
    }
   ],
   "source": [
    "validation = phi_data[phi_data.split=='validation']\n",
    "\n",
    "validation.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3382 entries, 57 to 39088\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0.1              3382 non-null   int64  \n",
      " 1   dfci_mrn                  3382 non-null   float64\n",
      " 2   cancer_type               3382 non-null   object \n",
      " 3   date                      3382 non-null   object \n",
      " 4   any_cancer                3382 non-null   int64  \n",
      " 5   progression               3382 non-null   int64  \n",
      " 6   response                  3382 non-null   int64  \n",
      " 7   Unnamed: 0                3382 non-null   int64  \n",
      " 8   text                      3382 non-null   object \n",
      " 9   PROVIDER_DEPARTMENT       3382 non-null   object \n",
      " 10  patient_id                3382 non-null   int64  \n",
      " 11  hybrid_death_ind          3382 non-null   object \n",
      " 12  hybrid_death_dt           2160 non-null   object \n",
      " 13  primary_cancer_diagnosis  3382 non-null   object \n",
      " 14  genomics_date             3382 non-null   object \n",
      " 15  after_profile             3382 non-null   int64  \n",
      " 16  split                     3382 non-null   object \n",
      "dtypes: float64(1), int64(7), object(9)\n",
      "memory usage: 475.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test = phi_data[phi_data.split=='test']\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = training.sample(n=100, random_state=42)\n",
    "sample_validation = validation.sample(n=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import LSTM, Linear, Embedding, Conv1d, MaxPool1d, GRU, LSTMCell, Dropout, Module, Sequential, ReLU\n",
    "\n",
    "   \n",
    "class LabeledModel(nn.Module):\n",
    "\n",
    "    def __init__(self, device='cuda'):\n",
    "        super(LabeledModel, self).__init__()\n",
    "        \n",
    "        self.longformer = AutoModel.from_pretrained('yikuan8/Clinical-Longformer')\n",
    "        self.any_cancer_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "        self.response_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "        self.progression_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x_text_tensor, x_attention_mask):\n",
    "        # x should be tuple of input IDs, then attention mask\n",
    "        global_attention_mask = torch.zeros_like(x_text_tensor, device='cuda')\n",
    "        # global attention on cls token\n",
    "        global_attention_mask[:, 0] = 1\n",
    "        main = self.longformer(x_text_tensor, x_attention_mask, global_attention_mask)\n",
    "        main = main.last_hidden_state[:,0,:].squeeze(1)\n",
    "\n",
    "                                          \n",
    "        any_cancer_out = self.any_cancer_head(main)\n",
    "        response_out = self.response_head(main)\n",
    "        progression_out = self.progression_head(main)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return any_cancer_out, response_out, progression_out\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class LabeledDataset(data.Dataset):\n",
    "    def __init__(self, pandas_dataset):\n",
    "        self.data = pandas_dataset.copy()\n",
    "        self.indices = self.data.index.unique()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\", truncation_side='left')        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # how many notes in the dataset\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data for notes corresponding to indices passed\n",
    "        this_index = self.indices[index]\n",
    "        pand = self.data.loc[this_index, :]\n",
    "        #label = torch.tensor(pand.progression, dtype=torch.float32)\n",
    "    \n",
    "        encoded = self.tokenizer(pand['text'], padding='max_length', truncation=True)\n",
    "\n",
    "        x_text_tensor = torch.tensor(encoded.input_ids, dtype=torch.long)\n",
    "        x_attention_mask = torch.tensor(encoded.attention_mask, dtype=torch.long)\n",
    "        \n",
    "        y_any_cancer = torch.tensor(pand.any_cancer, dtype=torch.float32)\n",
    "        y_response = torch.tensor(pand.response, dtype=torch.float32)\n",
    "        y_progression = torch.tensor(pand.progression, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "        return x_text_tensor, x_attention_mask, y_any_cancer, y_response, y_progression\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =  AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\", truncation_side='left')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = pd.concat([sample_train, sample_validation], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# inference on training_validation dataset for teacher model\n",
    "themodel = LabeledModel()\n",
    "themodel.load_state_dict(torch.load('dfci_phi_note_longformer_overfit_small_train.pt'))\n",
    "themodel.to('cuda')\n",
    "\n",
    "themodel.eval()\n",
    "\n",
    "no_shuffle_valid_dataset = data.DataLoader(LabeledDataset(train_validation), batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "output_true_lists = [[] for x in range(3)]\n",
    "output_prediction_lists = [[] for x in range(3)]\n",
    "for batch in no_shuffle_valid_dataset:\n",
    "    #thisframe = pd.DataFrame()\n",
    "    x_text_ids = batch[0].to('cuda')\n",
    "    x_attention_mask = batch[1].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        predictions = themodel(x_text_ids, x_attention_mask)\n",
    "    for j in range(3):\n",
    "        output_true_lists[j].append(batch[2+j].detach().cpu().numpy())\n",
    "        output_prediction_lists[j].append(predictions[j].detach().cpu().numpy())\n",
    "\n",
    "output_true_lists = [np.concatenate(x) for x in output_true_lists]        \n",
    "output_prediction_lists = [np.concatenate(x) for x in output_prediction_lists]\n",
    "\n",
    "\n",
    "output_validation = train_validation.copy()\n",
    "for x in range(3):\n",
    "    output_validation['outcome_' + str(x) + '_logit'] = output_prediction_lists[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = output_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation.to_csv('teacher_attack_dataset_small_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = pd.concat([sample_train, sample_validation], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# inference on training_validation dataset for student model\n",
    "themodel = LabeledModel()\n",
    "themodel.load_state_dict(torch.load('dfci_mimic_note_longformer_overfit_small_train.pt'))\n",
    "themodel.to('cuda')\n",
    "\n",
    "themodel.eval()\n",
    "\n",
    "no_shuffle_valid_dataset = data.DataLoader(LabeledDataset(train_validation), batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "output_true_lists = [[] for x in range(3)]\n",
    "output_prediction_lists = [[] for x in range(3)]\n",
    "for batch in no_shuffle_valid_dataset:\n",
    "    #thisframe = pd.DataFrame()\n",
    "    x_text_ids = batch[0].to('cuda')\n",
    "    x_attention_mask = batch[1].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        predictions = themodel(x_text_ids, x_attention_mask)\n",
    "    for j in range(3):\n",
    "        output_true_lists[j].append(batch[2+j].detach().cpu().numpy())\n",
    "        output_prediction_lists[j].append(predictions[j].detach().cpu().numpy())\n",
    "\n",
    "output_true_lists = [np.concatenate(x) for x in output_true_lists]        \n",
    "output_prediction_lists = [np.concatenate(x) for x in output_prediction_lists]\n",
    "\n",
    "\n",
    "output_validation = train_validation.copy()\n",
    "for x in range(3):\n",
    "    output_validation['outcome_' + str(x) + '_logit'] = output_prediction_lists[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = output_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation.to_csv('student_attack_dataset_small_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = pd.read_csv('teacher_attack_dataset_small_train.csv')\n",
    "train_validation['in_teacher_training'] = np.where(train_validation.split=='train',1.0,0.0)\n",
    "unique_mrns = pd.Series(train_validation.dfci_mrn.unique())\n",
    "attack_train_mrns = unique_mrns.sample(frac=0.6, random_state=42)\n",
    "attack_valid_mrns = unique_mrns[~ unique_mrns.isin(attack_train_mrns)]\n",
    "\n",
    "attack_train = train_validation[train_validation.dfci_mrn.isin(attack_train_mrns)]\n",
    "attack_valid = train_validation[train_validation.dfci_mrn.isin(attack_valid_mrns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 116 entries, 0 to 195\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0.2              116 non-null    int64  \n",
      " 1   Unnamed: 0.1              116 non-null    int64  \n",
      " 2   dfci_mrn                  116 non-null    float64\n",
      " 3   cancer_type               116 non-null    object \n",
      " 4   date                      116 non-null    object \n",
      " 5   any_cancer                116 non-null    int64  \n",
      " 6   progression               116 non-null    int64  \n",
      " 7   response                  116 non-null    int64  \n",
      " 8   Unnamed: 0                116 non-null    int64  \n",
      " 9   text                      116 non-null    object \n",
      " 10  PROVIDER_DEPARTMENT       116 non-null    object \n",
      " 11  patient_id                116 non-null    int64  \n",
      " 12  hybrid_death_ind          116 non-null    object \n",
      " 13  hybrid_death_dt           82 non-null     object \n",
      " 14  primary_cancer_diagnosis  116 non-null    object \n",
      " 15  genomics_date             116 non-null    object \n",
      " 16  after_profile             116 non-null    int64  \n",
      " 17  split                     116 non-null    object \n",
      " 18  outcome_0_logit           116 non-null    float64\n",
      " 19  outcome_1_logit           116 non-null    float64\n",
      " 20  outcome_2_logit           116 non-null    float64\n",
      " 21  in_teacher_training       116 non-null    float64\n",
      "dtypes: float64(5), int64(8), object(9)\n",
      "memory usage: 20.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attack_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train simple logistic regression model to predict if a given note was in teacher training set using outputs and labels\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "logreg = LogisticRegression(random_state=0, penalty=None).fit(attack_train[['any_cancer','progression','response','outcome_0_logit','outcome_1_logit','outcome_2_logit']], attack_train['in_teacher_training'])\n",
    "valid_preds = logreg.predict_proba(attack_valid[['any_cancer','progression','response','outcome_0_logit','outcome_1_logit','outcome_2_logit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc\n",
      "(0.7146908678389109, (0.5933068633011911, 0.8248084069524211))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from confidenceinterval.bootstrap import bootstrap_ci\n",
    "\n",
    "#random_generator = np.random.default_rng()\n",
    "random_generator=42\n",
    "print('auroc')\n",
    "print(bootstrap_ci(y_true=attack_valid['in_teacher_training'],\n",
    "             y_pred=valid_preds[:,1],\n",
    "             metric=roc_auc_score,\n",
    "             confidence_level=0.95,\n",
    "             n_resamples=1000,\n",
    "             method='bootstrap_bca',\n",
    "             random_state=random_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do student\n",
    "train_validation = pd.read_csv('student_attack_dataset_small_train.csv')\n",
    "train_validation['in_teacher_training'] = np.where(train_validation.split=='train',1.0,0.0)\n",
    "unique_mrns = pd.Series(train_validation.dfci_mrn.unique())\n",
    "attack_train_mrns = unique_mrns.sample(frac=0.6, random_state=42)\n",
    "attack_valid_mrns = unique_mrns[~ unique_mrns.isin(attack_train_mrns)]\n",
    "\n",
    "attack_train = train_validation[train_validation.dfci_mrn.isin(attack_train_mrns)]\n",
    "attack_valid = train_validation[train_validation.dfci_mrn.isin(attack_valid_mrns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 116 entries, 0 to 195\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0.2              116 non-null    int64  \n",
      " 1   Unnamed: 0.1              116 non-null    int64  \n",
      " 2   dfci_mrn                  116 non-null    float64\n",
      " 3   cancer_type               116 non-null    object \n",
      " 4   date                      116 non-null    object \n",
      " 5   any_cancer                116 non-null    int64  \n",
      " 6   progression               116 non-null    int64  \n",
      " 7   response                  116 non-null    int64  \n",
      " 8   Unnamed: 0                116 non-null    int64  \n",
      " 9   text                      116 non-null    object \n",
      " 10  PROVIDER_DEPARTMENT       116 non-null    object \n",
      " 11  patient_id                116 non-null    int64  \n",
      " 12  hybrid_death_ind          116 non-null    object \n",
      " 13  hybrid_death_dt           82 non-null     object \n",
      " 14  primary_cancer_diagnosis  116 non-null    object \n",
      " 15  genomics_date             116 non-null    object \n",
      " 16  after_profile             116 non-null    int64  \n",
      " 17  split                     116 non-null    object \n",
      " 18  outcome_0_logit           116 non-null    float64\n",
      " 19  outcome_1_logit           116 non-null    float64\n",
      " 20  outcome_2_logit           116 non-null    float64\n",
      " 21  in_teacher_training       116 non-null    float64\n",
      "dtypes: float64(5), int64(8), object(9)\n",
      "memory usage: 20.8+ KB\n"
     ]
    }
   ],
   "source": [
    "attack_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train attack model on student outputs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "logreg = LogisticRegression(random_state=0, penalty=None).fit(attack_train[['any_cancer','progression','response','outcome_0_logit','outcome_1_logit','outcome_2_logit']], attack_train['in_teacher_training'])\n",
    "valid_preds = logreg.predict_proba(attack_valid[['any_cancer','progression','response','outcome_0_logit','outcome_1_logit','outcome_2_logit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc\n",
      "(0.5456608054452637, (0.4305343473356578, 0.6620339549748387))\n"
     ]
    }
   ],
   "source": [
    "# evaluate attack model on student outputs\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from confidenceinterval.bootstrap import bootstrap_ci\n",
    "\n",
    "random_generator=42\n",
    "print('auroc')\n",
    "print(bootstrap_ci(y_true=attack_valid['in_teacher_training'],\n",
    "             y_pred=valid_preds[:,1],\n",
    "             metric=roc_auc_score,\n",
    "             confidence_level=0.95,\n",
    "             n_resamples=1000,\n",
    "             method='bootstrap_bca',\n",
    "             random_state=random_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
