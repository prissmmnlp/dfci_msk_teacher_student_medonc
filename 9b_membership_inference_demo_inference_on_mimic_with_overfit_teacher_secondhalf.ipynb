{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e38feb-8e8f-4474-aaf9-88c01be597c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook runs inference using the overfit DFCI teacher model on the MIMIC dataset \n",
    "# discharge summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d467b7a-01d4-4782-a827-8e425b3498b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes10/klkehl/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ee9478-ea4f-4f0c-a1eb-1ea3be1d4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharges = pd.read_csv('../data/discharge.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff326166-b987-4dc6-a0ca-43aadae6b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331794 entries, 0 to 331793\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   note_id     331794 non-null  object\n",
      " 1   subject_id  331794 non-null  int64 \n",
      " 2   hadm_id     331794 non-null  int64 \n",
      " 3   note_type   331794 non-null  object\n",
      " 4   note_seq    331794 non-null  int64 \n",
      " 5   charttime   331794 non-null  object\n",
      " 6   storetime   331777 non-null  object\n",
      " 7   text        331794 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 20.3+ MB\n"
     ]
    }
   ],
   "source": [
    "discharges.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805b1980-68ce-486b-8dbf-f2d00bd59067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3392896/3366294324.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cancer_discharges['text'] = cancer_discharges['text'].str.lower().str.replace('\\n', ' ')\n",
      "/tmp/ipykernel_3392896/3366294324.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cancer_discharges['text'] = cancer_discharges['text'].str.replace(r'\\s+', ' ', regex=True)\n"
     ]
    }
   ],
   "source": [
    "cancer_discharges = discharges[discharges.text.str.lower().str.contains('cancer|malignan')]\n",
    "cancer_discharges['text'] = cancer_discharges['text'].str.lower().str.replace('\\n', ' ')\n",
    "cancer_discharges['text'] = cancer_discharges['text'].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3687e8b9-859c-49fe-a9cb-c8dd996552be",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = cancer_discharges.head(cancer_discharges.shape[0]//2)\n",
    "second_half = cancer_discharges.tail(cancer_discharges.shape[0]//2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cda17c3-be74-4fba-a9c8-8c3d4642b344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70688, 8), (70689, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_half.shape, second_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87536f48-f820-4588-9a76-808938dda937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class UnLabeledDataset(data.Dataset):\n",
    "    def __init__(self, pandas_dataset):\n",
    "        self.data = pandas_dataset.copy()\n",
    "        self.indices = self.data.index.unique()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\", truncation_side='right')        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # how many notes in the dataset\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data for notes corresponding to indices passed\n",
    "        this_index = self.indices[index]\n",
    "        pand = self.data.loc[this_index, :]\n",
    "        #label = torch.tensor(pand.progression, dtype=torch.float32)\n",
    "    \n",
    "        encoded = self.tokenizer(pand['text'], padding='max_length', truncation=True)\n",
    "\n",
    "        x_text_tensor = torch.tensor(encoded.input_ids, dtype=torch.long)\n",
    "        x_attention_mask = torch.tensor(encoded.attention_mask, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        \n",
    "        return x_text_tensor, x_attention_mask\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b5eaf1-c0ef-40fb-897e-a9ee49d98951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import LSTM, Linear, Embedding, Conv1d, MaxPool1d, GRU, LSTMCell, Dropout, Module, Sequential, ReLU\n",
    "\n",
    "   \n",
    "class LabeledModel(nn.Module):\n",
    "\n",
    "    def __init__(self, device='cuda'):\n",
    "        super(LabeledModel, self).__init__()\n",
    "        \n",
    "        self.longformer = AutoModel.from_pretrained('yikuan8/Clinical-Longformer')\n",
    "        self.any_cancer_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "        self.response_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "        self.progression_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x_text_tensor, x_attention_mask):\n",
    "        # x should be tuple of input IDs, then attention mask\n",
    "        global_attention_mask = torch.zeros_like(x_text_tensor, device='cuda')\n",
    "        # global attention on cls token\n",
    "        global_attention_mask[:, 0] = 1\n",
    "        main = self.longformer(x_text_tensor, x_attention_mask, global_attention_mask)\n",
    "        main = main.last_hidden_state[:,0,:].squeeze(1)\n",
    "\n",
    "                                          \n",
    "        any_cancer_out = self.any_cancer_head(main)\n",
    "        response_out = self.response_head(main)\n",
    "        progression_out = self.progression_head(main)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return any_cancer_out, response_out, progression_out\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b01a87-dae4-46cc-9d1c-835d7e704f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# write out actual validation dataset\n",
    "themodel = LabeledModel()\n",
    "themodel.load_state_dict(torch.load('dfci_phi_note_longformer_overfit_small_train.pt'))\n",
    "themodel.to('cuda:0')\n",
    "\n",
    "themodel.eval()\n",
    "\n",
    "no_shuffle_valid_dataset = data.DataLoader(UnLabeledDataset(second_half), batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "output_prediction_lists = [[] for x in range(3)]\n",
    "for i, batch in enumerate(no_shuffle_valid_dataset):\n",
    "    #thisframe = pd.DataFrame()\n",
    "    x_text_ids = batch[0].to('cuda')\n",
    "    x_attention_mask = batch[1].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        predictions = themodel(x_text_ids, x_attention_mask)\n",
    "    for j in range(3):\n",
    "        output_prediction_lists[j].append(predictions[j].detach().cpu().numpy())\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "output_prediction_lists = [np.concatenate(x) for x in output_prediction_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce7ce4d5-d71d-4ef9-a932-6ccf4a7f9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = second_half.copy()\n",
    "for x in range(3):\n",
    "    output['outcome_' + str(x) + '_logit'] = output_prediction_lists[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0881515e-58f8-43c7-acca-bdb98b04c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('../data/second_half_discharges_overfit_small_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4f115-db95-41ce-9b6b-3c03ef6e9db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
